{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567b2daa-64e6-4e95-9901-95a64969b272",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate relevant result data and graphs for each BERTopic sub-model finalists post tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2ca05-65f7-4fa7-a40f-4b57321ba66f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bd82e9-a5ab-426d-ad7e-de3a63148875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NMT\\anaconda3\\envs\\Python39\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\NMT\\anaconda3\\envs\\Python39\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\NMT\\anaconda3\\envs\\Python39\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\NMT\\anaconda3\\envs\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\NMT\\anaconda3\\envs\\Python39\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c91c1f-851c-4aab-88e6-daafdc1622ad",
   "metadata": {},
   "source": [
    "Read raw csv file of data with CWE described by attributes in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df541070-938a-44bf-a84f-c8f66eb777b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "#file_path_input = '../Input/simulated_data_AllSoftware.csv'\n",
    "#file_path_input = '../Input/simulated_data_AllHardware.csv'\n",
    "file_path_input = '../Input/simulated_data_AllSoftwareHardware.csv'\n",
    "\n",
    "# Open the file\n",
    "with open(file_path_input, mode='r', encoding='utf-8') as file:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Read the headers (first row) into a list\n",
    "    #headers = next(csv_reader)\n",
    "    \n",
    "    # Create a list to store the data\n",
    "    raw_data = []\n",
    "    \n",
    "    # Loop through each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        # Append the row data as a list to the data list\n",
    "        raw_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24cafc-1ffb-4735-ae20-0828473c163d",
   "metadata": {},
   "source": [
    "Join all attributes(features) into one clear text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b630b7eb-df5c-4c51-bff1-00ce8ccaafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list to store the text data and cwe id list\n",
    "docs = []\n",
    "cwe_list = []\n",
    "feature_data = []\n",
    "\n",
    "for row in raw_data:\n",
    "    tmplst = [row[i] for i in range(1,len(row))]\n",
    "    docs.append(\" \".join(tmplst))\n",
    "    feature_data.append(tmplst)\n",
    "    cwe_list.append(str(row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a825f-b1ce-4c74-8429-85721a508b85",
   "metadata": {},
   "source": [
    "Load the saved text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fd9ac2-03a5-4a8b-9bbf-2d0aa3e6c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_filepathname1 = \"Embeddings/SBERT_raw.csv\"\n",
    "text_embeddings_sep = np.genfromtxt(embed_filepathname1, delimiter=',')\n",
    "\n",
    "embed_filepathname2 = \"Embeddings/SBERT_whole_doc.csv\"\n",
    "text_embeddings_whole = np.genfromtxt(embed_filepathname2, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37714ef-5bc3-4751-8345-9ffbcb331785",
   "metadata": {},
   "source": [
    "Functions for Dimension Reduction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0457823-71cd-440e-8b0e-daea138d61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "def get_umap(n_components, n_neighbors=15, min_dist=0.0, metric='cosine', random_state=42, verbose=False):\n",
    "    my_umap = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, metric=metric, \n",
    "                   random_state=random_state, verbose=verbose)\n",
    "    return my_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3892fd1e-d075-41ee-837f-0608211ba761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_pca(n_components=None):\n",
    "    my_pca = PCA(n_components=n_components, random_state=0)\n",
    "    return my_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74013e6a-d496-4b65-aec7-57748edd29d1",
   "metadata": {},
   "source": [
    "Functions for main Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9884cd7e-a02b-4257-8b49-c108c6a99e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "def get_hdbscan(min_cluster_size=2, min_samples=None, metric='euclidean', cluster_selection_method='eom', prediction_data=True):\n",
    "    my_hdbscan = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric=metric, \n",
    "                         cluster_selection_method=cluster_selection_method, prediction_data=prediction_data)\n",
    "    return my_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6142bff-da6f-4d2c-a96c-c3e3c5e3f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_kmeans(n_clusters, random_state=0):\n",
    "    my_kmeans = KMeans(n_clusters, n_init=\"auto\", random_state=random_state)\n",
    "    return my_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df43d7c-f279-4e7e-8f4e-07716d24eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def get_aggloClus(distance_threshold=0, n_clusters=None):\n",
    "    my_model = AgglomerativeClustering(distance_threshold=distance_threshold, n_clusters=n_clusters)\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc943f4-26ab-48bc-9eb3-9af0e075f6c4",
   "metadata": {},
   "source": [
    "Setup for Topic Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78973e40-6e67-4472-9dcc-b4edfe709f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "query_words = [\"cwe\", \"vulnerability\", \"vulnerabilities\", \"method\", \"methods\", \"technical\", \"impact\", \"security\", \"property\", \"properties\", \"severity\", \"likelihood\", \"relevant\", \"asset\", \"assets\", \"attack\", \"vector\", \"attacker\", \"type\", \"motive\", \"cyber\", \"controls\", \"countermeasure\", \"countermeasures\", \"detection\"]\n",
    "stop_words_ori = text.ENGLISH_STOP_WORDS\n",
    "stop_words = stop_words_ori.union(query_words)\n",
    "stop_words = stop_words.union(cwe_list)\n",
    "stop_words_cust = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447e1c67-de68-42f7-8d03-0c32326e39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_Vectorizer(ngram_range=(1, 2), stop_words=stop_words_cust): \n",
    "    my_Vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words=stop_words)\n",
    "    return my_Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24daf88e-eb37-4ece-838e-47674a1a2863",
   "metadata": {},
   "source": [
    "## Load parameters table of finalist sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8deeaea-d3e6-44ee-a278-1c51392a94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Parameters/SBERT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e585fd4b-7bc5-4c3f-8840-af3c0c1fbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = None\n",
    "df['probs'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b400b570-c1b6-4b73-b39b-78e85401179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>mode</th>\n",
       "      <th>embedder</th>\n",
       "      <th>dim_red</th>\n",
       "      <th>clus</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>n_components</th>\n",
       "      <th>labels</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>PCA</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>PCA</td>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>WHOLE</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>PCA</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>SEP</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>PCA</td>\n",
       "      <td>K-MEANS</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SN   mode embedder dim_red     clus  n_clusters  n_neighbors  \\\n",
       "0    1    SEP    SBERT    UMAP  HDBSCAN         NaN         15.0   \n",
       "1    2    SEP    SBERT    UMAP  HDBSCAN         NaN         15.0   \n",
       "2    3  WHOLE    SBERT    UMAP  HDBSCAN         NaN         25.0   \n",
       "3    4  WHOLE    SBERT    UMAP  HDBSCAN         NaN         30.0   \n",
       "4    5  WHOLE    SBERT    UMAP  K-MEANS        10.0         25.0   \n",
       "5    6  WHOLE    SBERT    UMAP  K-MEANS        10.0         25.0   \n",
       "6    7    SEP    SBERT    UMAP  K-MEANS        19.0         15.0   \n",
       "7    8    SEP    SBERT    UMAP  K-MEANS        19.0         20.0   \n",
       "8    9  WHOLE    SBERT     PCA  HDBSCAN         NaN          NaN   \n",
       "9   10    SEP    SBERT     PCA  HDBSCAN         NaN          NaN   \n",
       "10  11  WHOLE    SBERT     PCA  K-MEANS         7.0          NaN   \n",
       "11  12    SEP    SBERT     PCA  K-MEANS        28.0          NaN   \n",
       "\n",
       "    n_components labels probs  \n",
       "0             20   None  None  \n",
       "1             60   None  None  \n",
       "2             55   None  None  \n",
       "3             35   None  None  \n",
       "4             35   None  None  \n",
       "5             55   None  None  \n",
       "6             30   None  None  \n",
       "7             45   None  None  \n",
       "8             80   None  None  \n",
       "9             50   None  None  \n",
       "10            70   None  None  \n",
       "11            90   None  None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a13e776-6b44-4539-82db-ba5ca5b9f721",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Run for result data and graphs generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13db910b-8c69-4d99-8596-f572e226fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      " 35%|███▌      | 19/54 [00:00<00:00, 181.76it/s]\u001b[A\n",
      "100%|██████████| 54/54 [00:00<00:00, 189.31it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:14<02:44, 14.91s/it]\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\n",
      " 39%|███▉      | 20/51 [00:00<00:00, 193.18it/s]\u001b[A\n",
      "100%|██████████| 51/51 [00:00<00:00, 193.49it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:23<01:53, 11.35s/it]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      " 35%|███▌      | 19/54 [00:00<00:00, 189.00it/s]\u001b[A\n",
      "100%|██████████| 54/54 [00:00<00:00, 158.53it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:32<01:30, 10.01s/it]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 19/56 [00:00<00:00, 189.00it/s]\u001b[A\n",
      "100%|██████████| 56/56 [00:00<00:00, 195.66it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:39<01:12,  9.09s/it]\n",
      "100%|██████████| 9/9 [00:00<00:00, 169.78it/s]\n",
      " 42%|████▏     | 5/12 [00:46<00:57,  8.17s/it]\n",
      "100%|██████████| 9/9 [00:00<00:00, 169.77it/s]\n",
      " 50%|█████     | 6/12 [00:52<00:45,  7.51s/it]\n",
      "100%|██████████| 18/18 [00:00<00:00, 189.42it/s]\n",
      " 58%|█████▊    | 7/12 [01:00<00:37,  7.59s/it]\n",
      "100%|██████████| 18/18 [00:00<00:00, 201.05it/s]\n",
      " 67%|██████▋   | 8/12 [01:08<00:30,  7.68s/it]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 42/42 [00:00<00:00, 206.84it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [01:13<00:20,  6.84s/it]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 41/41 [00:00<00:00, 209.12it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [01:19<00:13,  6.62s/it]\n",
      "100%|██████████| 6/6 [00:00<00:00, 112.11it/s]\n",
      " 92%|█████████▏| 11/12 [01:23<00:05,  5.88s/it]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 27/27 [00:00<00:00, 180.89it/s]\u001b[A\n",
      "100%|██████████| 12/12 [01:28<00:00,  7.41s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loop for each sub-model\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    # read the parameters\n",
    "    sn = row['SN']\n",
    "    mode = row['mode']\n",
    "    embedder = row['embedder']\n",
    "    dim_red = row['dim_red']\n",
    "    clus = row['clus']\n",
    "    n_clusters = int(row['n_clusters']) if not np.isnan(row['n_clusters']) else None\n",
    "    n_neighbors = int(row['n_neighbors']) if not np.isnan(row['n_neighbors']) else None\n",
    "    n_components = int(row['n_components']) if not np.isnan(row['n_components']) else None\n",
    "    model_str = f\"{sn}-{mode}-{embedder}-{dim_red}-{clus}-{n_clusters}-{n_neighbors}-{n_components}\"\n",
    "    \n",
    "    # pick the corresponding model/component\n",
    "    if mode == \"SEP\":\n",
    "        text_embeddings = text_embeddings_sep\n",
    "    elif mode == \"WHOLE\":\n",
    "        text_embeddings = text_embeddings_whole\n",
    "\n",
    "    if dim_red == \"PCA\":\n",
    "        umap_model=get_pca(n_components=n_components)\n",
    "    elif dim_red == \"UMAP\":\n",
    "        umap_model=get_umap(n_components=n_components, n_neighbors=n_neighbors)\n",
    "\n",
    "    if clus == \"K-MEANS\":\n",
    "        hdbscan_model=get_kmeans(n_clusters=n_clusters, random_state=0)\n",
    "    elif clus == \"HDBSCAN\":\n",
    "        hdbscan_model=get_hdbscan(min_cluster_size=2, min_samples=None)\n",
    "    \n",
    "    # BERTopic pipeline\n",
    "    topic_model = BERTopic(\n",
    "    \n",
    "        # Pipeline models\n",
    "        embedding_model=None,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=get_Vectorizer(ngram_range=(1, 2), stop_words=stop_words_cust),\n",
    "        representation_model=None,\n",
    "    \n",
    "        # Hyperparameters\n",
    "        top_n_words=20,\n",
    "        verbose = False\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    topics, probs = topic_model.fit_transform(docs, text_embeddings)\n",
    "    df.at[index, 'labels'] = topics\n",
    "    df.at[index, 'probs'] = probs\n",
    "    with open(f'Labels_{model_str}.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for item in topics:\n",
    "            writer.writerow([item])\n",
    "    \n",
    "    # Create directory\n",
    "    os.makedirs('results/SBERT/' + model_str, exist_ok=True)\n",
    "    os.chdir('results/SBERT/' + model_str)\n",
    "    \n",
    "    # Generate topic info csv\n",
    "    topic_model.get_topic_info().to_csv(f'TopicInfo_{model_str}.csv', index=False)\n",
    "    # Generate barchart\n",
    "    topic_model.visualize_barchart(top_n_topics=12, n_words=10, height=400, width=250).write_html(f'Top12TopicsBarchart_{model_str}.html')\n",
    "    # Generate topics visualize graph\n",
    "    topic_model.visualize_topics().write_html(f'VisualizeTopic_{model_str}.html')\n",
    "\n",
    "    try:\n",
    "        # Generate hierarchical topics visualize graph\n",
    "        hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "        topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics).write_html(f'HierarchicalTopics_{model_str}.html')\n",
    "        \n",
    "        # Generate hierarchical topics tree csv\n",
    "        tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "        with open(f'HierarchicalTree_{model_str}.txt', 'w') as f:\n",
    "            f.write(tree)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Generate topics heatmap\n",
    "    topic_model.visualize_heatmap().write_html(f'Heatmap_{model_str}.html')\n",
    "    \n",
    "    # Generate visualize documents graph\n",
    "    reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(text_embeddings)\n",
    "    topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings).write_html(f'VisualizeDoc_{model_str}.html')\n",
    "\n",
    "    try:\n",
    "        # Generate visualize hierarchical documents graph\n",
    "        topic_model.visualize_hierarchical_documents(docs, hierarchical_topics, reduced_embeddings=reduced_embeddings).write_html(f'VisualizeHierDoc_{model_str}.html')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    os.chdir('../../..')\n",
    "\n",
    "# Save the dataframe with addtional labels and probabilities list\n",
    "df.to_csv('resultevals_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadcd58-e315-4bea-b50d-440185e4665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
